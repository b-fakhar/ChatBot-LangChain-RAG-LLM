{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["! pip install datasets transformers[sentencepiece]\n","import importlib"],"metadata":{"id":"b61H7dVb5DSv"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4U8aq4ECB27x"},"outputs":[],"source":["import                          torch, os\n","\n","import numpy                    as np\n","import pandas                   as pd\n","import matplotlib.pyplot        as plt\n","\n","from google.colab               import drive\n","from datasets                   import DatasetDict\n","from datasets                   import load_from_disk\n","from sklearn.preprocessing      import MultiLabelBinarizer"]},{"cell_type":"code","source":["print(\"Working Directory:\", os.getcwd())\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define the folder path\n","folder_path = \"/content/drive/MyDrive/NLP_class\"\n","\n","# Change the working directory to a specific path\n","os.chdir(folder_path)\n","# Print the updated working directory\n","print(\"Updated Working Directory:\", os.getcwd())"],"metadata":{"id":"EiBwkV_RnYyf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import utils\n","importlib.reload(utils)\n","from utils import df_to_DatasetDict, MyDataset, Trainer, Evaluator"],"metadata":{"id":"oVT5_ia3-cVs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"id":"Mv-sUcj-GkpC"}},{"cell_type":"code","source":["# Create folder to save dataset\n","dataset_dir = os.path.join(folder_path,'dataset')\n","os.makedirs(dataset_dir, exist_ok=True)\n","\n","# output dir\n","out_dir = os.path.join(folder_path,'results')\n","os.makedirs(os.path.join(folder_path,'results'), exist_ok=True)"],"metadata":{"id":"91sHax2rGmTZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# data_path = \"/content/drive/MyDrive/NLP_class/train.csv\"\n","# df = pd.read_csv(data_path)\n","# # combining 'title' and 'abstract' column to| get more context\n","# df['text'] = df['TITLE'] + \".\"+df['ABSTRACT']\n","# # dropping useless features/columns\n","# df.drop(labels=['TITLE', 'ABSTRACT', 'ID'], axis=1, inplace=True)\n","# # rearranging columns\n","# df = df[['text', 'Computer Science', 'Physics', 'Mathematics', 'Statistics',\n","#                      'Quantitative Biology', 'Quantitative Finance',]]\n","\n","# # Convert the label columns to a list of labels\n","# label_columns = [\"Computer Science\", \"Physics\", \"Mathematics\", \"Statistics\", \"Quantitative Biology\", \"Quantitative Finance\"]\n","# labels = df[label_columns].values.tolist()\n","\n","# # Combine the text column with the list of labels\n","# df[\"labels\"] = labels\n","\n","# # Drop the original label columns\n","# df.drop(columns=label_columns, inplace=True)\n","\n","# # Now df contains the \"text\" column and the \"labels\" column with lists of 1s and 0s\n","\n","# df.head()"],"metadata":{"id":"N2qVdDveHJYX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train_size = 0.8\n","# val_size   = 0.2\n","# test_size = None\n","# dataset_dir = dataset_dir\n","# df_to_DatasetDict(df,\n","#                   train_size,\n","#                   val_size,\n","#                   dataset_dir = dataset_dir,\n","#                   frac=1,\n","#                   random_state=200)\n","\n","# dataset = load_from_disk(os.path.join(dataset_dir))\n","# dataset"],"metadata":{"id":"6wAdm1PsMu-9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_path = \"https://raw.githubusercontent.com/laxmimerit/All-CSV-ML-Data-Files-Download/master/IMDB-Movie-Data.csv\"\n","usecols=[\"Description\", \"Genre\"]\n","df = pd.read_csv(data_path, usecols=usecols)\n","# df.head()\n","\n","multilabel = MultiLabelBinarizer()\n","\n","df['Genre'] = df['Genre'].str.split(',')\n","labels = multilabel.fit_transform(df['Genre']).astype('float32')\n","df['labels'] = list(labels)\n","\n","# Drop 'Genre' column\n","df.drop(columns=['Genre'], inplace=True)\n","\n","# Change the name of 'Description' column\n","df.rename(columns={'Description': 'text'}, inplace=True)  # Change column 'A' to 'New_A'\n","\n","df.head()"],"metadata":{"id":"F9kvIF1RNq2U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# df.columns"],"metadata":{"id":"B8QugtKtNy7p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_size = 0.7\n","val_size   = 0.2\n","test_size  = 0.1\n","dataset_dir = dataset_dir\n","df_to_DatasetDict(df,\n","                  train_size,\n","                  val_size,\n","                  test_size,\n","                  dataset_dir = dataset_dir)\n","\n","dataset = load_from_disk(os.path.join(dataset_dir))\n","dataset"],"metadata":{"id":"7p4w3CC9vsXO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_classes = len(dataset['train']['labels'][0])\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","trainer = Trainer(\n","                  dataset_dir,\n","                  out_dir,\n","                  num_classes,\n","                  patience = 10,\n","                  model_ckpt = \"distilbert-base-uncased\",\n","                  problem_type = \"multi_label_classification\",\n","                  max_len = 256,\n","                  optimizer = 'Adam',\n","                  init_lr = 1e-5,\n","                  weight_decay = 0,\n","                  scheduler_type = \"linear\",\n","                  num_epochs = 1,\n","                  train_bs = 32,\n","                  val_bs = 32,\n","                  device = device,\n","                  clf_thrshold = 0.3)"],"metadata":{"id":"zQISCaiuYVFk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"CpPjNvbiCr5X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ckpt_name = 'dump/run_12/training_checkpoint.pth'\n","# ckpt = torch.load(os.path.join(out_dir, ckpt_name))\n","# ckpt.keys()"],"metadata":{"id":"eUwuGl166fOR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluation"],"metadata":{"id":"v1gmIu9an_fH"}},{"cell_type":"code","source":["# dataset_dir = os.path.join(folder_path,'dataset')\n","# out_dir = os.path.join(folder_path,'results')\n","# model_dir = os.path.join(out_dir, 'dump/run_7')\n","\n","# num_classes = len(dataset['train']['labels'][0])\n","# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","# evaluator = Evaluator(dataset_dir,\n","#                       model_dir = model_dir,\n","#                       num_classes = num_classes,\n","#                       ckpt_name    = \"training_checkpoint.pth\",\n","#                       model_ckpt   = \"distilbert-base-uncased\",\n","#                       problem_type = \"multi_label_classification\",\n","#                       device       = device,\n","#                       clf_thrshold = 0.3)"],"metadata":{"id":"vd77z-EzoHFL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# evaluator.evaluate()"],"metadata":{"id":"cD0K88h0oHIN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Prediction"],"metadata":{"id":"EG6c9Vs-7QX6"}},{"cell_type":"code","source":[],"metadata":{"id":"7We4664QLslW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"P-R1NHs7LsoK"},"execution_count":null,"outputs":[]}]}